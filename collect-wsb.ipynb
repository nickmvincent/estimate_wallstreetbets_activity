{"cells":[{"cell_type":"markdown","source":"# Reddit Exploratory Data Collection Notebook\n\nThis notebook contains contain to collected time-sampled data from subreddits of your choosing.\n\nThe end result is that csv files are written to `data/`, and the idea is that you will load these files in\nanother notebook for analysis.","metadata":{"tags":[],"cell_id":"00000-73a344bb-185c-43ce-b446-8f70f6711ea0","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"34ef5ad1","execution_millis":150,"deepnote_to_be_reexecuted":false,"cell_id":"00001-6fe1ee0c-e5ef-41fe-90d8-b21e9ed7d333","execution_start":1612552008754,"deepnote_cell_type":"code"},"source":"# imports\nimport pandas as pd\nimport requests\nimport time\nimport random\nfrom datetime import datetime, timedelta\nimport asyncpraw\nimport os\nimport numpy as np","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"e0f100ea","execution_millis":2,"cell_id":"00002-d0f62fca-2308-49dc-a629-2556e6362f4e","execution_start":1612552009235,"deepnote_cell_type":"code"},"source":"def chunks(lst, n):\n    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"53a515f7","execution_millis":2,"cell_id":"00003-1f1732ab-a3b2-4c9d-b606-ceadeddede39","execution_start":1612552009649,"deepnote_cell_type":"code"},"source":"# init PRAW reddit object. Used to grab most up-to-date post scores.\nreddit = asyncpraw.Reddit(\n     client_id=os.environ['CLIENT_ID'],\n     client_secret=os.environ['CLIENT_SECRET'],\n     user_agent=\"dataleverage_research scripts (by u/nickmvincent@gmail.com)\"\n )","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"f18b550a","execution_millis":8,"cell_id":"00004-48309189-7a36-4955-9bb1-da48443f6ab4","execution_start":1612552010253,"deepnote_cell_type":"code"},"source":"# generate time windows to sample from\n\ndef generate_windows(\n    start, end, window_size\n):\n    \"\"\"\n    start -  datetime object, the first timestamp\n    end - datetime object, the last timestamp\n    window_size - timedelta object, how long is each window (i.e. \"cluster\")?\n\n    ret - a list of 2-tuples. Each tuples has 2 datetime objects. each is the start of a window.\n    \"\"\"\n    ret = [(start, start+window_size)]\n    while start < end:\n        start += window_size\n        ret.append((start, start+window_size))\n    return ret\n\nstart_dt = datetime(2021, 1, 1)\nend_dt = datetime(2021, 2, 1)\nwindow_size = timedelta(minutes=1)\nn = 0.01\n\nwindows = generate_windows(start_dt, end_dt, window_size)\n\nseed = 0\nif n is not None:\n    random.seed(seed)\n    if n < 1:\n        print('treating n as frac')\n        n = int(len(windows) * n)\n        print('len windows, n', len(windows), n)\n    chosen_windows = random.sample(windows, n)\nelse:\n    chosen_windows = windows\n\nchosen_windows_as_timestamps = [\n    (int(x[0].timestamp()), int(x[1].timestamp())) \n    for x in chosen_windows\n]","outputs":[{"name":"stdout","text":"treating n as frac\nlen windows, n 44641 446\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"2944415d","execution_millis":11,"cell_id":"00005-4043c65b-c0c1-407e-aa39-d01b99c8cccf","execution_start":1612552010764,"deepnote_cell_type":"code"},"source":"len(windows), len(chosen_windows)","outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(44641, 446)"},"metadata":{}}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":null,"execution_millis":19,"cell_id":"00006-72e4cec8-66d5-46de-8a98-f63288173f48","execution_start":1612552011236,"output_cleared":true,"deepnote_cell_type":"code"},"source":"# review the time windows we \"chose\"\nsorted([\n    (str(x[0]), str(x[1])) for x in sorted(chosen_windows)\n])","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"aa924ea1","execution_millis":1,"cell_id":"00007-fe894d8b-1c1f-41e6-94af-6e1868aa3984","execution_start":1612552011507,"deepnote_cell_type":"code"},"source":"# subs = pd.read_csv('sub_5000.csv')\n# subreddit_chunks = list(\n#     chunks(subs.sort_values('subscribers', ascending=False).display_name, 50))\n# # for chunk in subreddit_chunks:\n# #     print(','.join(chunk))","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"4bdb0a16","execution_millis":5,"cell_id":"00010-4a5c671d-7fd1-48d5-ac96-25283fc8e759","execution_start":1612552012094,"deepnote_cell_type":"code"},"source":"def helper(x):\n    return str(x).replace(' ', '_')\n\nstart_ts = helper(start_dt)\nend_ts = helper(end_dt)\n\nprint(start_dt.timestamp(), end_dt.timestamp())\nprint(start_ts, end_ts)","outputs":[{"name":"stdout","text":"1609459200.0 1612137600.0\n2021-01-01_00:00:00 2021-02-01_00:00:00\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"325451db","execution_millis":9,"cell_id":"00011-ac5b00bf-c497-49cf-aba4-6935b1b2175d","execution_start":1612552012538,"deepnote_cell_type":"code"},"source":"n","outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"446"},"metadata":{}}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"ddeb4b9a","execution_millis":1,"is_code_hidden":false,"output_cleared":false,"cell_id":"00012-cdcfb01e-cfe0-48fc-813c-fa0fb1892904","execution_start":1612552012954,"deepnote_cell_type":"code"},"source":"def get_posts(endpoint, **kwargs):\n    params = {k: v for k, v in kwargs.items() if v is not None}\n    url = f'https://api.pushshift.io/reddit/{endpoint}/search/'\n    r = requests.get(url, params=kwargs)\n    try:\n        ret = r.json()\n    except Exception as e:\n        print(e, r, r.request.body)\n        ret = None\n    return ret\n\n\ndef scrape(endpoint, subreddit, chosen_windows_as_timestamps, score_criteria):\n    PUSHSHIFT_MAX = 100\n    count = 0\n    total_retries = 0\n    #windows_covered = []\n    fails = []\n    times = []\n    times_per_post = []\n\n\n    subd = f'data/start={start_ts}_end={end_ts}_n={n}_seed={seed}'\n    try:\n        os.mkdir(subd)\n    except:\n        pass\n    if subreddit is not None:\n        name = subreddit[:10]\n    else:\n        name = 'all'\n    for window_index, (start, end) in enumerate(chosen_windows_as_timestamps):\n        t1 = time.time()\n\n        cur = start\n        filename = f'{subd}/{endpoint}_{name}_{helper(start)}_{helper(end)}_score={score_criteria}.csv'\n        posts_within_window = []\n        df = None\n        window_as_dt = (datetime.fromtimestamp(start), datetime.fromtimestamp(end))\n        print('start: {}, end: {}, window: {} / {}'.format(\n            datetime.fromtimestamp(start), datetime.fromtimestamp(end),\n            window_index, len(chosen_windows_as_timestamps)\n        ))\n        while True:\n            retries = 0\n            time.sleep(1)\n            #windows_covered.append(\n            #    (datetime.fromtimestamp(cur), datetime.fromtimestamp(end)))\n            json = get_posts(\n                endpoint=endpoint,\n                subreddit=subreddit,\n                size=PUSHSHIFT_MAX,\n                before=end,\n                after=cur,\n                sort='asc',\n                sort_type='created_utc',\n                score=score_criteria\n            )\n            # increment API call count\n            count += 1\n            if json is None:\n                time.sleep(2)\n                retries +=1\n                total_retries += 1\n                if retries > 3:\n                    fails.append(window_as_dt)\n                    break\n                continue\n            posts = json['data']\n\n            for post in posts:\n                post['window'] = window_as_dt\n            # if we get zero posts, time to move to the next time window\n            if len(posts) == 0:\n                break\n            posts_within_window += posts\n\n            df = pd.DataFrame(posts_within_window)\n            # print every 10 calls, just to keep track\n            if count % 10 == 0:\n                print('count', count)\n\n            # increment our \"after\" param to the last post\n            cur = posts[-1]['created_utc']\n            \n            # max # of posts from pushshift is 100\n\n            if len(posts) < PUSHSHIFT_MAX: # don't need to keep looking through this window\n                break\n        if df is not None:\n            # TODO: drop unneeded columns to save space?\n            df.to_csv(filename, index=False)\n        seconds_elapsed = time.time() - t1\n        times.append(seconds_elapsed)\n        if len(posts) != 0:\n            times_per_post.append(seconds_elapsed / len(posts))\n        else:\n            times_per_post.append(None)\n\n\n    #all_df = pd.DataFrame(all_posts)\n    deets = {\n        'api_call_count': count,\n        'total_retries': total_retries,\n        'fails': fails,\n        'times': times,\n        'times_per_posts': times_per_post,\n    }\n    return deets","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":null,"execution_millis":7860292,"cell_id":"00013-c591d498-7f0e-438d-a131-ef3d92b40d51","execution_start":1612552013437,"output_cleared":true,"deepnote_cell_type":"code"},"source":"t1 = time.time()\nsubmission_stats = scrape('submission', None, chosen_windows_as_timestamps, score_criteria = None)\ntic = time.time() - t1\nprint('tic', tic)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00012-30997139-b34e-4bb3-8332-a77b5035ff02","deepnote_to_be_reexecuted":true,"source_hash":null,"execution_millis":5,"output_cleared":true,"deepnote_cell_type":"code"},"source":"np.mean(submission_stats['times'])","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00014-d8b1d01d-113c-496b-802a-f832a0dd5c65","deepnote_to_be_reexecuted":true,"source_hash":null,"execution_millis":6,"output_cleared":true,"deepnote_cell_type":"code"},"source":"np.mean([x for x in submission_stats['times_per_posts'] if x is not None])","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00015-63c1862b-e13b-4833-8488-c60806f0839b","deepnote_to_be_reexecuted":true,"source_hash":"5839e124","execution_millis":3,"deepnote_cell_type":"code"},"source":"t1 = time.time()\n\ndo_comment = False\nif do_comment:\n    scrape('comment', None, chosen_windows_as_timestamps, score_criteria = None)\n    tic = time.time() - t1\n    print('tic', tic)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00016-21c39a79-0c7e-464a-b3c3-db4211979a8f","deepnote_to_be_reexecuted":true,"source_hash":null,"execution_millis":23075,"output_cleared":true,"deepnote_cell_type":"code"},"source":"import glob\nsubmission_dfs = []\nfolder = 'start=2021-01-01_00:00:00_end=2021-02-01_00:00:00_n=446_seed=0'\nfor name in glob.glob(f'data/{folder}/submission_*'):\n    submission_dfs.append(pd.read_csv(name))\nprint(len(submission_dfs))\nsubmissions = pd.concat(submission_dfs)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00018-33d3d98e-dbc3-4a17-9532-c8af2534dc7d","deepnote_to_be_reexecuted":true,"source_hash":"3c9fdc61","execution_millis":2833,"deepnote_cell_type":"code"},"source":"submissions['dt'] = submissions.created_utc.apply(datetime.fromtimestamp)\nsubmissions['date'] = submissions['dt'].apply(datetime.date)\nsubmissions['weekday'] = submissions.dt.apply(datetime.weekday)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use PRAW to get most update to date scores and # comments\nIt seems scores tend to be way off for very recent posts, whereas num_comments is very close.","metadata":{"tags":[],"cell_id":"00019-01640f43-2120-4781-9e9c-63dc9d974335","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":true,"source_hash":null,"execution_millis":6343612,"output_cleared":true,"cell_id":"00016-01fc2709-e59a-4462-83f2-01a7fbf7d09a","deepnote_cell_type":"code"},"source":"# this example may be useful: https://old.reddit.com/r/redditdev/comments/akv79c/getting_latest_submission_scores_for_lots_of/\n\ntimes = []\npraw_scores = {}\npraw_num_comments = {}\nnum_chunks = 0\nfor chunk in chunks(submissions.id, 100):\n    t1 = time.time()\n    num_chunks += 1\n    if num_chunks % 10 == 0:\n        print('starting a chunk', len(chunk), len(praw_scores))\n    list_of_ids = []\n    for submission_id in chunk:\n        list_of_ids.append(\"t3_{}\".format(submission_id))\n    \n    if list_of_ids:\n        reddit_submissions = reddit.info(fullnames=list_of_ids)\n        time.sleep(1)\n        async for submission in reddit_submissions:\n            praw_scores[submission.id] = submission.score\n            praw_num_comments[submission.id] = submission.num_comments\n    tic = time.time() - t1\n    times.append(tic)\n    #print(praw_scores)\nsubmissions['praw_score'] = submissions.id.map(praw_scores)\nsubmissions['praw_num_comments'] = submissions.id.map(praw_num_comments)\nsubmissions.to_csv(f'data/{folder}/submissions_with_praw.csv')","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00020-c8e906de-2872-4b2c-a56e-48c6c18d09bd","deepnote_to_be_reexecuted":true,"source_hash":null,"execution_millis":4,"output_cleared":true,"deepnote_cell_type":"code"},"source":"import numpy as np\nnp.sum(times) /3600","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00020-fe8752c3-ba64-4c75-ba31-a09de1177bde","deepnote_to_be_reexecuted":true,"source_hash":null,"execution_millis":89,"output_cleared":true,"deepnote_cell_type":"code"},"source":"submissions.groupby('subreddit').praw_score.sum().sort_values(ascending=False)[:20] / submissions.praw_score.sum()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00024-80c65d32-4ed9-477d-9baa-a541b3a157b3","deepnote_to_be_reexecuted":true,"source_hash":"b623e53d","execution_millis":1899,"deepnote_cell_type":"code"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=9d8dd8e7-abf2-4721-84cd-03779d208ef5' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"1c7f8089-8308-4378-b550-5478714b6a98","deepnote_execution_queue":[],"deepnote":{}}}